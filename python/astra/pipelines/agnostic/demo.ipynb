{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "ww7hFk28jV"
      },
      "source": [
        "# Demonstration of AgnosticQA methods\n",
        "### Riley Thai, 27 October 2023"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "a5NxpsUnNo"
      },
      "source": [
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "import numpy as np"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "GUI event loop hook disabled.\n"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "owMOy5pG0H"
      },
      "source": [
        "Preamble for my system to load code directory of the repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "gFkpQjUq4K"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/home/riley/uni/rproj/code\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "gZXjheS9n0"
      },
      "source": [
        "# First look at data.\n",
        "\n",
        "First step is reading in and cleaning the files -- this should become antequated since we want to read SQL tables instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "2EvLe7PsBy"
      },
      "source": [
        "from astropy.table import Table\n",
        "from cleaners import clean_ASPCAP\n",
        "\n",
        "t = Table.read(\"/home/riley/uni/rproj/data/allASPCAPVisit-0.4.0.fits\").to_pandas()\n",
        "data = clean_ASPCAP(t)\n",
        "data"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "        ID SDSS_ID HEALPIX  ... RAW_E_TI_2_H RAW_V_H RAW_E_V_H\n24030  NaN     NaN     NaN  ...          NaN     NaN       NaN\n24031  NaN     NaN     NaN  ...          NaN     NaN       NaN\n54810  NaN     NaN     NaN  ...          NaN     NaN       NaN\n54811  NaN     NaN     NaN  ...          NaN     NaN       NaN\n18194  NaN     NaN     NaN  ...          NaN     NaN       NaN\n...    ...     ...     ...  ...          ...     ...       ...\n24778  NaN     NaN     NaN  ...          NaN     NaN       NaN\n71845  NaN     NaN     NaN  ...          NaN     NaN       NaN\n43323  NaN     NaN     NaN  ...          NaN     NaN       NaN\n43288  NaN     NaN     NaN  ...          NaN     NaN       NaN\n71805  NaN     NaN     NaN  ...          NaN     NaN       NaN\n\n[36344 rows x 331 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "oGQmWCQyF0"
      },
      "source": [
        "We can see that this is just the standard ASPCAP output table, except the cleaning routine masks those with invalid paramter values or uncertainties.\n",
        "\n",
        "We can do some very simple exploratory analysis of our dataset with one of our plotter functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "tcXYZFy4xj"
      },
      "source": [
        "from plotters import plot_uncertainties_hist\n",
        "\n",
        "plot_uncertainties_hist(data,show=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "zAdEpzW5hP"
      },
      "source": [
        "The above plot showcases a logarithmic histogram of the uncertainties of our given parameters.\n",
        "\n",
        "The \"show\" option is specifically implemented for notebook workflows. It's the same as doing any plotter function with a show call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "OLIC38lccH"
      },
      "source": [
        "plot_uncertainties_hist(data)\n",
        "plt.show(block=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "LH9vfwbTmV"
      },
      "source": [
        "# Visit Frequencies\n",
        "\n",
        "As a simple introduction, let's use the example of visit frequencies to see how things are implemented. We do the following for everything.\n",
        "\n",
        "1. Pass it through a calculation method.\n",
        "2. Pass this output table through a plotting method(s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "eXvvQDkmDx"
      },
      "source": [
        "# calculation\n",
        "from calculators import calculate_visit_frequency\n",
        "\n",
        "visit_data = calculate_visit_frequency(data, fn=\"AllASPCAPVisit-0.4.0\",write=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "SIi0Vzbc6M"
      },
      "source": [
        "# plotting\n",
        "from plotters import plot_visit_frequency\n",
        "\n",
        "plot_visit_frequency(visit_data)\n",
        "plt.show(block=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "KsMUOHrfrf"
      },
      "source": [
        "# Uncertainty z-scores (pairwise distance comparisons)\n",
        "\n",
        "The main thing I did for this undergrad project was pairwise distance comparisons to assess how uncertainties reflected actual measurement variations.\n",
        "\n",
        "This is what we call the 'z-score'.\n",
        "\n",
        "We can calculate some z-scores for effective temperature ($T_{\\mathrm{eff}}$) and metallicity ($\\mathrm{[Fe/H]}$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Rr2XttL2Fe"
      },
      "source": [
        "from calculators import calculate_pairwise_distance\n",
        "\n",
        "z_data = calculate_pairwise_distance(data, [\"TEFF\", \"FE_H\"], \"allASPCAPVisit-0.4.0\", write=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Time for calculation: 7.019311485000799\n"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "gOBEGVZasn"
      },
      "source": [
        "Data is stored in a nice table, where everything is indexed by the same key as the original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "bxoc4itnyQ"
      },
      "source": [
        "z_data"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "            TEFF  FE_H\n0      -1.337591   NaN\n1            NaN   NaN\n2            NaN   NaN\n3            NaN   NaN\n4            NaN   NaN\n...          ...   ...\n273687       NaN   NaN\n273688       NaN   NaN\n273689       NaN   NaN\n273690       NaN   NaN\n273691       NaN   NaN\n\n[273692 rows x 2 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "kxp0niFE25"
      },
      "source": [
        "We can plot basic histograms of z-scores, with some fractional adjustments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Lxl82EV2Rk"
      },
      "source": [
        "from plotters import plot_pairwise\n",
        "\n",
        "plot_pairwise(z_data, show=True)\n",
        "plot_pairwise(z_data, adjust='frac',show=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "MiulBHphFD"
      },
      "source": [
        "Each of the plotters functions also saves each figure as its own PDF file. The filepath can be customized with the \"figpath\" option.\n",
        "\n",
        "Too, the specific variable(s) to plot can be specified with the vars option. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "eToiV5FcUG"
      },
      "source": [
        "plot_pairwise(z_data,vars=[\"TEFF\"],figpath='./',show=False) "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "DaMHiE0zPM"
      },
      "source": [
        "Each plotting method is hard-coded in its output, but can be customized with options, and is adaptive to the data given to it.\n",
        "\n",
        " If we want to instead view it altogether, we can use the \"overlap\" option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "UjoMtU8st8"
      },
      "source": [
        "plot_pairwise(z_data, overlap=True,show=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "rE1Z7EPEuv"
      },
      "source": [
        "Next, lets recalculate our z-scores, adding in some additional systematic uncertainties, and another set with a gridsearched 3 parameter error model.\n",
        "\n",
        "Here I'm using an option to force the lower bound on the uncertainty cleaning routine to be zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "cH5B9lrAnk"
      },
      "source": [
        "data = clean_ASPCAP(t, zero_lower_bound=True)\n",
        "z_data = calculate_pairwise_distance(data, [\"TEFF\", \"FE_H\"], \"allASPCAPVisit-0.4.0\", write=True, gridsearch= True, adjust=True)\n",
        "\n",
        "# we must mask any infinities from the division in the z-score calculation\n",
        "z_data.replace([np.inf, -np.inf], np.nan, inplace=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "TEFF: 0.9870594251353614 || (array([46.79252078]), array([100.]), array([100.]))\nFE_H: 1.0034592653730792 || (array([0.04679252]), array([0.1]), array([0.57368421]))\nTime for calculation: 38.893130237998776\n"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "LaZZZwtVxg"
      },
      "source": [
        "Note the \"write\" parameter, which saves it as a parquet file. Parquet is used because it's just very good and fast (especially compared to fits tables)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "5gHasw1DfQ"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import date\n",
        "%timeit pd.read_parquet(f\"data/z_{date.today()}_allASPCAPVisit-0.4.0.parquet\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "25.8 ms +- 361 us per loop (mean +- std. dev. of 7 runs, 10 loops each)\n"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "tfoEpUyrzy"
      },
      "source": [
        "Here, the parameter values are saved in a *sketchy* way. Any added systematic uncertainty has a XXX+10, where 10 is replaced with the added uncertainty. \n",
        "\n",
        "Gridsearch is \"_GS\", and the parameters are also saved as _tX, where X is the parameter number\n",
        "\n",
        "It should be noted that if we want to save these as fits for legacy, we need a different method of storing them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "1uLR6Nvf44"
      },
      "source": [
        "z_data"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "            TEFF  TEFF+10.0  TEFF+25.0  ...   FE_H_t0  FE_H_t1   FE_H_t2\n0      -1.337591  -1.323694  -1.245670  ...  0.046793      0.1  0.573684\n1      -2.905979  -2.426800  -1.427224  ...       NaN      NaN       NaN\n2      -1.154266  -0.744745  -0.345436  ...       NaN      NaN       NaN\n3       1.689043   1.067025   0.489291  ...       NaN      NaN       NaN\n4       6.092155   4.245802   2.068219  ...       NaN      NaN       NaN\n...          ...        ...        ...  ...       ...      ...       ...\n435901       NaN        NaN        NaN  ...       NaN      NaN       NaN\n435902       NaN        NaN        NaN  ...       NaN      NaN       NaN\n435903       NaN        NaN        NaN  ...       NaN      NaN       NaN\n435904       NaN        NaN        NaN  ...       NaN      NaN       NaN\n435905       NaN        NaN        NaN  ...       NaN      NaN       NaN\n\n[435906 rows x 28 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "8YWNVWegUH"
      },
      "source": [
        "# theta 1, for example\n",
        "z_data[\"TEFF_t1\"]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "0         100.0\n1           NaN\n2           NaN\n3           NaN\n4           NaN\n          ...  \n435901      NaN\n435902      NaN\n435903      NaN\n435904      NaN\n435905      NaN\nName: TEFF_t1, Length: 435906, dtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "jGPCAZyTVP"
      },
      "source": [
        "Notice all the NaN's of empty space. \n",
        "\n",
        "Plotting..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "wAHGnuLUGq"
      },
      "source": [
        "plot_pairwise(z_data, adjust=\"sys\",show=True)\n",
        "plot_pairwise(z_data, overlap=True, adjust=\"grid\",show=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "TQkgv947dW"
      },
      "source": [
        "To have a look at the impact of our added uncertainties, let's plot how it changes the standard dev. of the z-score distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "mld38Oe9Np"
      },
      "source": [
        "from plotters import plot_added_uncertainty_sigma\n",
        "\n",
        "plot_added_uncertainty_sigma(z_data,show=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "ZvZe6ZaMfO"
      },
      "source": [
        "We can do a surface density plot for the uncertainties of our gridsearched uncertainties to have a look at which error parameters are dominant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ZG0mlThzLO"
      },
      "source": [
        "from plotters import plot_binned_statistic\n",
        "\n",
        "additive = z_data[\"FE_H_t2\"].dropna().values*z_data[\"FE_H_TEFF\"].dropna().values + z_data[\"FE_H_t1\"].dropna().values * z_data[\"FE_H_SNR\"].dropna().values + z_data[\"FE_H_t0\"].dropna().values\n",
        "plot_binned_statistic(z_data[\"FE_H_TEFF\"].dropna().values,additive,xlabel=r'$T_{\\mathrm{eff}}$',ylabel=r\"$\\sigma_+$\",show=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "<Figure size 760x940 with 2 Axes>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "UtgGKETkuK"
      },
      "source": [
        "# Coadd Delta\n",
        "\n",
        "Now I'm going to calculate the coadd delta -- the difference between the visit and coadd values. To do this, we first must specify the stars file in the cleaning routine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "jvxT9QJSdU"
      },
      "source": [
        "from calculators import calculate_coadd_delta\n",
        "from util import Lookup\n",
        "from astropy.table import Table\n",
        "from cleaners import clean_ASPCAP\n",
        "\n",
        "t1 = Table.read(\"data/allASPCAPVisit-0.4.0.fits\").to_pandas()\n",
        "t2 = Table.read(\"data/allASPCAPStar-0.4.0.fits\").to_pandas()\n",
        "\n",
        "data_visits,data_stars = clean_ASPCAP(t1,t2)\n",
        "\n",
        "# drop rows above SNR > 200\n",
        "data_visits = data_visits.mask(data_visits[\"SNR\"] > 200)\n",
        "\n",
        "coadd_data = calculate_coadd_delta(data_visits, data_stars,\"allASPCAP-0.4.0\", write=False)\n",
        "coadd_data"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "             TEFF   LOGG   FE_H  ...    V_H         SNR  TELESCOPE\n0       55.356934  0.123  0.058  ...    NaN   33.973999   b'apo1m'\n1       74.845703  0.131  0.035  ...    NaN   82.559898   b'apo1m'\n2      203.166016  0.357  0.126  ...    NaN  135.419006   b'apo1m'\n3      140.775879  0.352  0.046  ...    NaN   72.371902   b'apo1m'\n4        9.197021  0.009  0.001  ...    NaN   25.364201  b'apo25m'\n...           ...    ...    ...  ...    ...         ...        ...\n18771    0.822998  0.053  0.013  ...  0.024   66.715500  b'lco25m'\n18772    4.293945  0.058  0.022  ...  0.001   57.420399  b'lco25m'\n18773   12.010010  0.002  0.023  ...  0.044   55.549801  b'lco25m'\n18774    8.687988  0.025  0.019  ...  0.025   60.342098  b'lco25m'\n18775    0.321045  0.011  0.005  ...  0.112   58.738499  b'lco25m'\n\n[18776 rows x 27 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "j6hMdgpRsU"
      },
      "source": [
        "We can do a few types of plots comparing the coadd delta to the SNR, such as these binned plots that compare median coadd delta to SNR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "2bsHHO8rR8"
      },
      "source": [
        "from plotters import plot_delta_coadd, plot_compare_coadd_snr\n",
        "\n",
        "\n",
        "plot_delta_coadd(coadd_data, vars=[\"LOGG\"],show=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "u8E93NYnxr"
      },
      "source": [
        "We can also use any callable statistic array operation, such as the root mean square."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ErScvNzlVW"
      },
      "source": [
        "from util import rms\n",
        "plot_delta_coadd(coadd_data, vars=[\"TI_H\"],type=rms,show=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "8DUsm81nsS"
      },
      "source": [
        "We can also do plots grouped by nucleosynthetic processes. Here, these ones also overplot the precision targets for the survey."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "HYODCnUqdx"
      },
      "source": [
        "plot_compare_coadd_snr(coadd_data,show=True)\n",
        "\n",
        "plot_compare_coadd_snr(coadd_data,compare_telescope=True,show=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ALERT: O_H all NaN for APO\nALERT: SI_H all NaN for APO\nALERT: S_H all NaN for APO\nALERT: TI_H all NaN for APO\nALERT: N_H all NaN for APO\n"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "AwLz9oNAVJ"
      },
      "source": [
        "from datetime import date\n",
        "print(date.today())\n",
        "print(matplotlib.__version__)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-27\n",
            "3.7.1\n"
          ]
        }
      ],
      "execution_count": 12
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}